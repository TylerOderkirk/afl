
1) Introduction
---------------

Every copy of afl-fuzz will take up one full CPU core. This means that on an
n-core system, you can safely run up to n different fuzzing jobs with virtually
no performance hit.

When targeting multiple unrelated binaries, it is perfectly fine to run fully
separate instances of afl-fuzz - be it on a single machine or across a large
fleet. The picture gets more complicated when you want to have multiple fuzzers
hammering a common target: if a hard-to-hit but interesting test case is
synthesized by one fuzzer, the remaining instances will not be able to use that
input to guide their work.

To help with this problem, afl-fuzz offers a simple way to synchronize test
cases on the fly.

2) Single-system parallelization
--------------------------------

If you wish to parallelize a single job across multiple cores on a single
system, simply create a new, empty output directory that will be shared by all
the instances of afl-fuzz; and then asign a unique alphanumeric ID to every
instance, passing it in the -S parameter when invoking the tool, e.g.:

$ ./afl-fuzz -o /path/to/sync_dir -S fuzzer01 [...other params...]

This syntax will cause the fuzzer to write its output to a directory called:

  /path/to/sync_dir/fuzzer01/

In this setup, each instance will periodically rescan all entries in
/path/to/sync_dir to find outputs discovered by other jobs. Note that -S also
implies -d and makes the fuzzer proceed straight to non-deterministic tweaks.

Of course, it is important to assign every fuzzer a different ID. Care should
be exercised when using the -f option, too: two processes competing to write
to the same file is bad news.

3) Multi-system parallelization
-------------------------------

The basic operating principle for multi-system parallelization is similar to
the mechanism explained in section 2, except that you need to write a simple
script that performs two actions:

  - Uses SSH with authorized_keys to connect to every machine and copy over
    a tar archive of the /path/to/sync_dir/<fuzzer_id>/queue/ directory for
    every <fuzzer_id> local to the machine, e.g.:

    ssh user@host7 'tar -cf - sync/host7_1/queue sync/host7_2/queue' >host7.tar

  - Distributes and unpacks these files on all the remaining machines, e.g.:

    ssh user@host8 'tar -kxf -' <host7.tar

When developing this code, there are several optimizations to keep in mind:

  - The synchronization doe not have to happen very often; running the
    script every 30 minutes or so may be pefectly fine.

  - There is no need to synchronize crashes/ or hangs/; you only need to
    copy over queue/*.

  - It is not necessary (and not advisable!) to overwrite existing files;
    the -k option in tar is a good choice.

  - There is no need to fetch directories for fuzzers that are not running
    locally on a particular machine.

4) Closing remarks
------------------

It is perhaps worth noting that it is OK to run some of the synchronized
instances with different input files, have them invoke the target binary
in a different way, or even have them use different (but related) target
binaries.

In some situations, you may want one fuzzer in a synchronized bunch to
still perform deterministic fuzzing, too. To enable this, you can use the
sort-of-undocumented -D option in the command line.
